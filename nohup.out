Error processing line 1 of /home/qzhb/anaconda3/lib/python3.7/site-packages/movienet-tools-nspkg.pth:

  Traceback (most recent call last):
    File "/home/qzhb/anaconda3/lib/python3.7/site.py", line 168, in addpackage
      exec(line)
    File "<string>", line 1, in <module>
    File "<frozen importlib._bootstrap>", line 580, in module_from_spec
  AttributeError: 'NoneType' object has no attribute 'loader'

Remainder of file ignored
loading dictionary from data/dictionary_TDIUC.pkl
Namespace(buffer_replacement_strategy='random', config_name='TDIUC_streaming', data_order=None, expt_name='TDIUC_streaming_qtype_2e-3', full=False, icarl=False, lr=0.002, max_buffer_size=None, network='mcan', offline=True, rehearsal_mode=None, remind_compressed_features=False, remind_features=False, remind_original_data=False, sampling_method='random', stream=False)
Building Dataloaders !
Loading Train Data !
Filtering Train Data !
Loading Test Data
Filtering Test Data
main.py:525: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_dict = yaml.load(f)
Net(
  (embedding): Embedding(9318, 300)
  (lstm): LSTM(300, 512, batch_first=True)
  (img_feat_linear): Linear(in_features=2048, out_features=512, bias=True)
  (backbone): MCA_ED(
    (enc_list): ModuleList(
      (0): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (1): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (2): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (3): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (4): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (5): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
    )
    (dec_list): ModuleList(
      (0): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (1): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (2): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (3): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (4): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (5): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
    )
  )
  (attflat_img): AttFlat(
    (mlp): MLP(
      (fc): FC(
        (linear): Linear(in_features=512, out_features=512, bias=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (linear): Linear(in_features=512, out_features=1, bias=True)
    )
    (linear_merge): Linear(in_features=512, out_features=1024, bias=True)
  )
  (attflat_lang): AttFlat(
    (mlp): MLP(
      (fc): FC(
        (linear): Linear(in_features=512, out_features=512, bias=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (linear): Linear(in_features=512, out_features=1, bias=True)
    )
    (linear_merge): Linear(in_features=512, out_features=1024, bias=True)
  )
  (proj_norm): LayerNorm()
  (proj): Linear(in_features=1024, out_features=188, bias=True)
)
Using lr specified in args 0.002
{
    "buffer_replacement_strategy": "random",
    "config_name": "TDIUC_streaming",
    "data_order": null,
    "expt_name": "TDIUC_streaming_qtype_2e-3",
    "full": false,
    "icarl": false,
    "lr": 0.002,
    "max_buffer_size": null,
    "network": "mcan",
    "offline": true,
    "rehearsal_mode": null,
    "remind_compressed_features": false,
    "remind_features": false,
    "remind_original_data": false,
    "sampling_method": "random",
    "stream": false
}
TRAINING
CURRENT TIME ====== Fri May 14 21:08:21 2021
/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 188])) is deprecated. Please ensure they have the same size.
  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
Traceback (most recent call last):
  File "main.py", line 571, in <module>
    main()
  File "main.py", line 560, in main
    training_loop(config, net, train_data, val_data, optimizer, criterion, config.expt_dir, net_running, start_epoch)
  File "main.py", line 163, in training_loop
    acc, vqa_acc = train_epoch(net, criterion, optimizer, train_data, epoch, __C=__C)
  File "main.py", line 116, in train_epoch
    loss = criterion(p, aidx)
  File "/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py", line 516, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py", line 2372, in binary_cross_entropy
    "!= input nelement ({})".format(target.numel(), input.numel()))
ValueError: Target and input must have the same number of elements. target nelement (128) != input nelement (24064)
Error processing line 1 of /home/qzhb/anaconda3/lib/python3.7/site-packages/movienet-tools-nspkg.pth:

  Traceback (most recent call last):
    File "/home/qzhb/anaconda3/lib/python3.7/site.py", line 168, in addpackage
      exec(line)
    File "<string>", line 1, in <module>
    File "<frozen importlib._bootstrap>", line 580, in module_from_spec
  AttributeError: 'NoneType' object has no attribute 'loader'

Remainder of file ignored
loading dictionary from data/dictionary_TDIUC.pkl
Namespace(buffer_replacement_strategy='random', config_name='TDIUC_streaming', data_order=None, expt_name='TDIUC_streaming_qtype_2e-3', full=False, icarl=False, lr=0.002, max_buffer_size=None, network='mcan', offline=True, rehearsal_mode=None, remind_compressed_features=False, remind_features=False, remind_original_data=False, sampling_method='random', stream=False)
Building Dataloaders !
Loading Train Data !
Filtering Train Data !
Loading Test Data
Filtering Test Data
main.py:528: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_dict = yaml.load(f)
Net(
  (embedding): Embedding(9318, 300)
  (lstm): LSTM(300, 512, batch_first=True)
  (img_feat_linear): Linear(in_features=2048, out_features=512, bias=True)
  (backbone): MCA_ED(
    (enc_list): ModuleList(
      (0): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (1): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (2): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (3): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (4): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
      (5): SA(
        (mhatt): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
      )
    )
    (dec_list): ModuleList(
      (0): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (1): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (2): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (3): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (4): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
      (5): SGA(
        (mhatt1): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (mhatt2): MHAtt(
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_merge): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn): FFN(
          (mlp): MLP(
            (fc): FC(
              (linear): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU(inplace=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (linear): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm1): LayerNorm()
        (dropout2): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm()
        (dropout3): Dropout(p=0.1, inplace=False)
        (norm3): LayerNorm()
      )
    )
  )
  (attflat_img): AttFlat(
    (mlp): MLP(
      (fc): FC(
        (linear): Linear(in_features=512, out_features=512, bias=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (linear): Linear(in_features=512, out_features=1, bias=True)
    )
    (linear_merge): Linear(in_features=512, out_features=1024, bias=True)
  )
  (attflat_lang): AttFlat(
    (mlp): MLP(
      (fc): FC(
        (linear): Linear(in_features=512, out_features=512, bias=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (linear): Linear(in_features=512, out_features=1, bias=True)
    )
    (linear_merge): Linear(in_features=512, out_features=1024, bias=True)
  )
  (proj_norm): LayerNorm()
  (proj): Linear(in_features=1024, out_features=188, bias=True)
)
Using lr specified in args 0.002
{
    "buffer_replacement_strategy": "random",
    "config_name": "TDIUC_streaming",
    "data_order": null,
    "expt_name": "TDIUC_streaming_qtype_2e-3",
    "full": false,
    "icarl": false,
    "lr": 0.002,
    "max_buffer_size": null,
    "network": "mcan",
    "offline": true,
    "rehearsal_mode": null,
    "remind_compressed_features": false,
    "remind_features": false,
    "remind_original_data": false,
    "sampling_method": "random",
    "stream": false
}
TRAINING
CURRENT TIME ====== Fri May 14 21:11:34 2021
p torch.Size([128, 188])
ans torch.Size([128])
/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 188])) is deprecated. Please ensure they have the same size.
  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
Traceback (most recent call last):
  File "main.py", line 574, in <module>
    main()
  File "main.py", line 563, in main
    training_loop(config, net, train_data, val_data, optimizer, criterion, config.expt_dir, net_running, start_epoch)
  File "main.py", line 166, in training_loop
    acc, vqa_acc = train_epoch(net, criterion, optimizer, train_data, epoch, __C=__C)
  File "main.py", line 119, in train_epoch
    loss = criterion(p, aidx)
  File "/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py", line 516, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/home/qzhb/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py", line 2372, in binary_cross_entropy
    "!= input nelement ({})".format(target.numel(), input.numel()))
ValueError: Target and input must have the same number of elements. target nelement (128) != input nelement (24064)
